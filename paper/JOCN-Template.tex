\documentclass[10pt,twocolumn,twoside]{osajnl}
%\usepackage[backend=bibtex, defernumbers=true]{biblatex}


\journal{jocn}

% Set the article type for journal submissions. Comment out this line for Optica Open preprint submissions.
\setboolean{shortarticle}{false}
% true = letter / tutorial
% false = research / review article
%\addbibresource{bib.bib}

\title{”Picture Perfect or Ethically Problematic?” \\ Ethical Implications of AI-generated Images on the Example of DALL$\cdot$E 2}

\author[1]{Sofia Kaltwasser}
\author[2]{Manuel Mühlberger}

\affil[1]{University of Potsdam}
\affil[2]{School of Computation, Information and Technology, TU Munich}


%% To be edited by editor
% \dates{Compiled \today}

%% To be edited by editor
%% \doi{\url{http://dx.doi.org/10.1364/XX.XX.XXXXXX}}

\begin{abstract}
JOCN article style and format is being updated to conform to Optica journal style and format. This new template is now required for preparing a research article for submission to the \emph{Journal of Optical Communications and Networking}. Consult the \href{https://www.opg.optica.org/submit/templates/}{Author Style Guide} for general information about manuscript preparation. Authors may also \href{https://opticaopen.org}{submit articles} prepared using this template to the Optica Publishing Group preprint server, \href{https://preprints.opticaopen.org}{Optica Open}. However, doing so is optional. Please refer to the submission guidelines found there. Note that copyright and licensing information should no longer be added to your Journal or Optica Open manuscript.
\end{abstract}

\setboolean{displaycopyright}{false} % Do not include copyright or licensing information in submission.

\begin{document}

\maketitle

\section{Introduction}
“I’m fascinated by this imagery. I love it. And it think everyone should see it” is what Jason M. Allen told CNN Business in an interview after winning first prize in the “digital arts/digitally-manipulated photography” category at the Colorado State Fair Fine Arts Competition\cite{JasonMAllenCNN}.
His artwork "Théâtre D’opéra Spatial" (Figure \ref{Theatre}) which he did not draw himself, but was rather generated by an Artificial Intelligence (AI) image generator, raises the question, whether the AI or the human has become the artist and whether Allen is really deserving of the prize.
As these systems become more widespread and accessible, issues such as bias, ownership and control over the generated content will become increasingly relevant, making in-depth critical and ethical analysis vital to ensure that the advantages of this technology are achieved without any detrimental effects. 
This paper will, on the example of DALL-E 2, highlight a select few ethical issues which are likely to come up when using AI image generation systems en masse. 
Thereafter, they will be analysed based upon two fundamental moral principles, namely, the categorical imperative and utlilitarianism. 
It will also shed light on the current state of regulations, or often times lack thereof and juxtapose it with the seemingly arbitrary terms of service that many providers publish. 
Finally, an outlook will be given on current research activity and active efforts in the European Union (EU) for establishing legal liability. 
\begin{figure}[htbp]
	\centering
	\fbox{\includegraphics[width=.85\linewidth]{images/ColoradoStateFairWinner.png}}
	\caption{“Théâtre D’opéra Spatial”, Winner of the blue ribbon in the fair’s contest for emerging digital artists by Colorado State Fair’s annual art competition, generated by MidJourneyAi\cite{OperaSpecial}.}
	\label{Theatre}
\end{figure}

\section{Technical Background of DALL-E 2}
In recent years, applications for computer vision and methods for processing images have considerably benefitted from developments made possible by deep learning and AI. 
One of these methods is picture synthesis, which is the act of creating new images and modifying ones that already exist. 
Because of its many useful applications in fields including art creation, image editing, virtual reality, video games, and computer-aided design, image synthesis is a extensive and significant field of research.\\
Text-conditional image models are capable of generating images from text queries and can arrange unrelated objects in a semantically plausible way. They are also called text-to-image models.
One of the most popular examples of such models is Open AI's Dall-E 2 \cite{DallE}.\\ 
%%or images in different styles that can be specified by natural language text queries and has 
DALL-E 2 is a powerful text-to-image synthesis model, released by Open AI in July 2022, capable of extracting the semantic meaning of natural text input and translating it in a zero-shot manner \cite{zeroShot} into high quality images, as can be seen in Figure \ref{exampleTapir}.
Zero-shot learning describes the process of classifying instances during normal usage that were not part of the training set \cite{mfdp}.
In this specific case, this refers to the ability of the user to input text at will that could not have been predicted during training.
It has the potential to be employed in a range of applications, like in creative design. For instance, a digital artist could significantly profit from this technology either by 
finding quick inspiration or by drastically increasing both the speed and the quality of his artwork if he has a certain picture of it in mind.
Overall, it marks a substantial leap in the field of generative models, especially compared to its predecessors DALL-E 1 or DALL-E mini, who where one of the first models that were suitable for the mass\cite{}%TODO: CITATION. 
However, to be able to gauge its possibilities, limitations and draw meaningful ethical conclusions, it is vital to first gain an understanding of its technical backbones.
The following technical background section of this paper will provide an overview of the architecture as well as the training process of DALL-E 2. 


\begin{figure}[htbp]
	\centering
	\includegraphics[width=.7\linewidth]{images/DallEExampleTapir.png}
	\caption{Four generated pictures to the text input: "a tapir with the texture of an accordion" \cite{zeroShot}}
	\label{exampleTapir}
\end{figure}

\subsection{Transformer Model}
Vaswani et al. introduced the Transformer model architecture in 2017 \cite{transformer} that has since become the state-of-the-art natural language processing model, whereupon many other models are based.\\
At its core, the transformer is a self-attention-based architecture that operates on sequences of tokens, such as words or subwords. The model contains an encoder and a decoder, each of which consist of a stack of identical layers.\\
Each layer in the transformer is composed of two sub-layers: a self-attention mechanism and a feed-forward network. The self-attention mechanism computes a weighted sum of the input sequence, where the weights are based on the similarity between each token and every other token in the sequence. This allows the model to attend to different parts of the input sequence at different layers, and has been shown to be highly effective at capturing long-range dependencies in language.\\
The feed-forward network applies a set of linear and non-linear transformations to the output of the self-attention mechanism, providing an additional layer of modeling capacity. \\
Apart from that, the transformer features a number of significant modifications in addition to the conventional self-attention mechanism that have proven essential to its success. Multi-head attention, which enables the model to pay attention to various points in the input sequence at once, is one such breakthrough. Another is the use of positional encodings, which provide the model knowledge about the tokens' order in the input sequence.

\subsection{High-level Abstraction of the Text-To-Image Model}
In order to encode the semantic meaning of the corresponding text, DALL-E 2 first processes a textual input description using a transformer-based language model. The multi-stage generative model which creates the final high-resolution image uses the encoded text as input to create an initial low-resolution image that is steadily improved over time, following a diffusion model. The generative model, which creates the image using a combination of transformer- and convolutional-based neural network architectures \cite{T2IReview}. 
%TODO: FINISH SENTENCE?

\begin{figure} [h]
	\centering
	\fbox{\includegraphics[width = 0.9\linewidth]{images/highLevel.png}}
	\caption{A CLIP text embedding is given to an autoregressive or diffusion algorithm to create an image embedding, which is then used to condition a diffusion decoder to create the final picture in the text-to-image production process.[modified from \cite{CLIP}]}
	%\label{exampleHighLevel}
\end{figure}

\subsection{Training Data}
250 million images and their related textual descriptions were collected from the internet as training data for the first model of DALL-E.\\
It was then trained using a two-stage training procedure \cite{zeroShot}:
\begin{enumerate}
	\item Each 256x256 RGB image was compressed into a 32x32 grid of image tokens with a total of 8192 potential values using a discrete variational autoencoder (dVAE). This results in a factor of 192 reduction in the transformer's context size without noticeably degrading visual quality.
	\item To simulate the joint distribution over the text and picture tokens, an autoregressive transformer is trained using up to 256 BPE-encoded text tokens and 32 x 32 = 1024 image tokens.
\end{enumerate}


\section{Ethical Approaches}
As image synthesis is a relatively young and emerging topic, it can be advantageous to rest the ethical assessment upon applicable philosophical approaches as a known point of reference.
For our evaluation, we have chosen two of the most well-known ethical concepts, namely, the categorial imperative as well as utilitarianism. These two are well suited for the corresponding analysis not only because of their prominence, but also their 
very different points of view.\\
Both will later on be used to perform the ethical analysis and illustrate considerations, potential consequences and the moral principles involved.
By contrasting the categorical imperative with the utlilitarianism approach, it is possible to arrive at a more nuanced and informed understanding of the topic, while also highlighting any potential ethical dilemmas that may arise.

\subsection{Kant}
The german philosopher Immanuel Kant (1724--1804) introduced the categorical imperative in his book "Groundwork of the Metaphysic of Morals" in 1785. \\
Kant formulated the categorical imperative as followed: "Act only according to that maxim by which you can at the same time will that it should become a universal law". 
It is a moral principle which states that actions should be taken based on whether they can be willed as a universal law for all individuals in all situations. 
In other words, an action is only morally right if it can be applied to everyone without contradiction.
Although it has been heaviliy critisized for its abstractness and inflexibility it is still very much relevant today and has a significant role to play in modern ethics and can be applied to a wide range of topics. %TODO: QUELLE!


\subsection{Utilitarianism}
Utilitarianism is an ethical theory that delineates right from wrong by focusing on outcomes. It is a form of consequentialism.
The theory assumes that the most ethical decision is the one that produces the greatest utility for the greatest number of people. It is based on ideas of Jeremy Bentham (1748--1832) and John Stuart Mill (1806--1873).\\
As this concept focuses on the consequences resulting from an action, all possible outcomes and their utilities, so both advantages and costs are taken into account to derive 
an ethical assessment.
%Due to the way, it takes advantages and costs into account, 
Moreover, it is also the method of moral reasoning that is most frequently applied in business \cite{EthicsUnwrapped} and is the moral system that is most known to defend using force or going to war. \\
However, utilitarian ethical decision-making also has its limits. Often times the exact consequences of an action are not certainly predictable.


\subsection{An Ethical Example - The Trolley Problem}
The well-known ethical dilemma called "The Trolley Problem" is well suited to emphasize these two concepts' differences in ethical assessment. 
The Trolley Problem describes a fictional scenario, a thought experiment, in which a spectator has the choice to rescue five people who are in danger of being hit by a trolley, by diverting the trolley to kill just one other person. 
A utilitarianist would pull the lever and save the five people, since the utility of saving five lives is higher than the one of only saving one. A Kantist on the other hand
does not value consequences and would therefore not pull the lever, as one should not kill one person to save five other lives since killing another individual will also be immoral in Kantian ethics. 


\section{What Ethical Challenges exist?}
Like with any emerging technology, there do not only come possibilities, but also challenges society has to face in its usage.
The ability to synthesize images from a text input by the user gives great potential for misuse. \\
Companies like Open AI try to train their models to decline inappropriate requests, but the line between inappropriate and acceptable requests is blurred and difficult to pin down precisely. 
Besides that, there are also models like Stable Diffusion \cite{StableDiffusion} available, which, as of now, cannot be regulated in a meaningful way. 
This is the case because it is open-source in nature and anybody can modify or distribute the source code, so that there does not exist a single point of liability.
In this section a handful of problems will be outlined that are later on to be analysed with the help of the aforementioned moral principles.

\subsection{Social Biases}
Text-to-image generative models have been shown to have varying amounts of biases, especially gender and skin tone biases. 
When the model is prompted with seemingly neutral phrases (such as "a photo of a nurse") that include no indications to, for example, skin tone or gender, it is nevertheless likely to produce images that are biased towards a certain complexion.
In the above example the generative model is heavily biased towards generating images of white women, as can be seen in Figure \ref{PhotoOfANurse}. 
More specifically, in this example, Stable Diffusion, a competitor to DALLE-2, overwhelmingly generates images of white women, the often times associated stereotype to this profession.
In particular, a study by scientists from UNC Chapel Hill where these biases were measured by the variance of the gender/skin tone distribution through both automated and human evaluation
was able to determine a clear relationship between the training data - labeled images - and the skin tone/ gender biases\cite{DallEval}. 
Although these images were not created by DALLE-2 itself, the same phenomenon can be observed for DALLE-2 \cite{DalleSocialBias}. The example of Stable Diffusion is referred to here, since the 
amount of data and visualization options are more plentiful, whereas data for DALLE-2 is still scarce. TODO: reinforces STEREOTYPES!!!!

\begin{figure}[htbp]
	\centering
	\fbox{\includegraphics[width = 0.6\linewidth]{images/PhotoOfNurse.png}}
	\caption{Example of social bias: with the prompt "a photo of a nurse". Modified from \cite{DallEval}.}
	\label{PhotoOfANurse}
\end{figure}


\subsection{Portrayal of racism, porn, illegal actions}
Another downside of DALLE-2 which should not be left out are the negative consequences that center around one's ability to generate any image at will. 
Therefore, it is inevitable, that malicious actors will eventually generate harmful, forbidden or illegal imagery. 
Although AI model companies try to restrict what can be generated from a prompt, as discussed in \ref{section:6}, there will always be workarounds to circumvent these safety-restrictions.
Consequently, it is possible to generate images that for instance could portray a child smoking which to our western mindset represents an illegal action. 
Apart from that, other contents harmful to society could be of pornographic or racist nature and may even be considered a felony such as generating child pornography. 


\subsection{Deception, Political Propaganda and Extremism}
One of the biggest dangers encompassing AI generated images are politically motivated and abusive contents like so-called deepfakes\footnote[1]{TEST}. 
Especially in the current times of social media, where uploaded contents go viral\footnote[2]{"Used to describe something that quickly becomes very popular or well known by being published on the internet [...]"\cite{viral}.} within minutes or hours and where does not exist a dedicated supervisory authority, the danger of FakeNews being spread across
a country or even the whole globe is tremendously large and can bring about severe damage. \\ 
For example on March 23rd, 2023, Donald Trump, the former president of the United States, had images circulate of him 
were he allegedly resisted arrest and was tackled to the ground by the police. This image was uploaded on Twitter and has been viewed over five million times in a few days. Despite the fact that the original creator 
only ever intended for it to be a joke, the AI-generated picture has still drawn a lot of attention within this short timeframe\cite{trump}. In this case, the creator clarified that the image 
was not real and no harm was intended, however in other scenarios where indeed malicious intentions are present, differentiating a fake image from a real one may be problematic and may also lead to severe reputation damage.
\\
Apart from that, another threat to the wellbeing of society is political propaganda and extremism.



Use in combination with chatgpt, ...

\begin{figure}[htbp]
	\centering
	\fbox{\includegraphics[width = 0.6\linewidth]{images/GameCoverArtCapitolInsurrection.png}}
	\caption{Jan 6. U.S. Capitol insurrection video game art generated by MidJourneyAI, modified from \cite{AIPropaganda}.}
	%\label{exampleHighLevel}
\end{figure}




\section{Ethical Examination}
Taking into account all of the aforementioned aspects, it is of significantly relevant to examine whether the use of image generating models in malicious edge cases is ethically justifiable, when considering the extensive consequences
that they may entail. 
QUESTIONS
These questions will be evaluated ethically, from the Kantian point of view as well as the Utilitarian perspective, in the following sections. 




%Is it ethically acceptable to generate pictures of others without their permission or propaganda material that influences many people after publication. What about pornography or even child pornography?\\
%In the following section, we address the question of which ethical decision-making justifies which application of image generation models.

\subsection{Kant}
Kant's categorical imperative implies that all people should behave in a certain way if they want everyone else to do the same.
Applied to image-generation with AI that would mean everyone should only generate the images they want to see or think it is ethical to generate.
However, since everyone has a different view of what is ethically justifiable to generate the categorical imperative is not a suitable ethical theory to evaluate the ethical boundaries of image generation.

\subsection{Utilitarianism}
According to Utilitarianism the good or pleasure originated of the AI-generated images has to be taken into account to decide if its an ethically justifiable action. \\
The pleasure derived from the generated picture has to be taken into account.
A distinction needs to be made between generating an image and making it public. With the publication of a picture the circle of people who can be harmed or pleased by it becomes much larger and other orders of magnitude have to be weighed against each other.\\
If the image is not made public only the pleasure of the person that entered the query has to be taken. \\
There are different scenarios that can occur where from a utilitarian point of view it would be ethically justifiable to generate certain content or images, even if they harm a person or a group of people, this is a consequence of weighing the production of the greatest good. \\
To stay with the propaganda example: If a person were to create material that harmed a politician's reputation so that he would not be re-elected, but that politician had harmed more people than he had helped or pleased during his time in office, it would be morally acceptable from a utilitarian standpoint to create the damaging content.\\
Taken another example of child pornography, which is illegal to possess, produce and distribute in most countries. Generating it does not harm any child as a consequence of the action but in order to generate such content it is very likely that similar images are present in the training data. So children were harmed in advance to make this action possible.\\ Utilitarianism only takes the consequences of an action into account, thus the preliminary events would not be considered. \\
Here another weakness of utilitarianism comes into view: the consequences of an action cannot be predicted exactly.\\
Does it keep pedophiles who can generate images of children's pornography from obtaining content from other sources, which would be not ethical justifiable from a utilitarian point of view?

\section{What is currently being done?}
\label{section:6}
Open AI states in their Terms of Service (TOS) that DALLE 2's capacity to produce violent, hateful, or pornographic images is constrained. 
DALLE 2's exposure to these ideas is reduced by "removing the most explicit content from the training data". 
"Advanced methods are also employed to prevent the photorealistic generation of real people's faces, particularly those of public figures."
And if filters detect text prompts and image uploads that might be against their policies, no images are generated. To prevent abuse, both automated and human monitoring mechanisms are employed \cite{DallE}. \\
-Simple Watermark\\
-strict regulation in China\\
-no regulation in the west (eu ai law proposal?)\\

\subsection{Data Labeling}
A TIME's investigation revealed that OpenAI used outsourced Kenyan laborers to label text snippets of violence, hate speech, and sexual abuse to generate training data for their ChatGPT’s (Chat Generative Pre-trained Transformer) predecessor, GPT-3 (Generative Pre-trained Transformer 3) that uses deep learning techniques to generate human-like text and engage in conversational interactions and payed them less than 2 usd per hour \cite{KenyaExclusive}. The continuous exposure of people to this content is very likely to cause psychological consequences.

\section{What could be done?}
\subsubsection*{Limit Training Data}
To hinder text-to-image models from generating inappropriate images the training data can be limited but therefore data that is inappropriate from a commonsense morality  point of view must be labeled as such. But overall quality could degrade depending on how many and which training data are left out.\\
Other models can be trained to recognize immoral pictures and texts but human supervising is also needed.
In order to prevent people from constantly being confronted with textual or pictorial images of violence, companies could join forces and make their already labeled data available to others and use already existing databases like the Socio-Moral Image Database \cite{Database}.



\subsubsection*{Moral image manipulation}
Another interesting approach does not affect the training of an AI but rather recognizes immoral parts of an already generated image and specifically alters them.
Park et al. introduced  %\cite{MoralEditing} 
a model recognizing visual commonsense immorality of a given picture, localizes the immoral parts of the image and manipulates it into a morally-qualifying alternative, see figure %\ref{moralEditing}.

\begin{figure}[htbp]
		\centering
		\fbox{\includegraphics[width= 0.95\linewidth]{images/moralAltering.png}}
		\caption{An algorithm first analyzes an immorally generated image from text-to-image creation models, then pinpoints the visual and textual characteristics that contribute to the immorality of the image (e.g., smoking). Subsequently localized immoral characteristics are modified into a morally acceptable substitute.\cite{MoralEditing}}
			%\label{moralEditing}
\end{figure}

\section{Conclusion}
 
%\begin{figure}[htbp]
%\centering
%\fbox{\includegraphics[width=.8\linewidth]{sample}}
%\caption{False-color image, where each pixel is assigned to one of seven reference spectra.}
%\label{fig:falsecolor}
%\end{figure}


\bigskip


%\bibliographystyle{unsrt}
\bibliography{bib.bib}
%\printbibliography[type=article, heading=subbibliography, title={Artikel}]
\end{document}
